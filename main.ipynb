{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905eace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.llama import llama\n",
    "from src.postgres_db import VectorDB\n",
    "\n",
    "OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\", \"http://ollama:11434\")\n",
    "MODEL = \"llama3.2:1b\" # Find available models here https://ollama.com/library\n",
    "EMBEDDING_MODEL = \"granite-embedding:30m\" # Find available models here https://ollama.com/library\n",
    "\n",
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\", \"vector-postgres\")\n",
    "\n",
    "vectordb = VectorDB(host=POSTGRES_HOST)\n",
    "llm = llama(OLLAMA_HOST, model=MODEL, embedding_model=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7aad5",
   "metadata": {},
   "source": [
    "## Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b94168",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How much do github actions cost for linux 4-core running for 3000 mins per month?\"\n",
    "embedding = llm.create_embedding(f\"{prompt}\")\n",
    "similar_docs = vectordb.search_similar(embedding, top_k=3)\n",
    "context=\"\"\n",
    "for doc in similar_docs:\n",
    "    context += doc[1] + \"\\n\"\n",
    "\n",
    "prompt_with_context = f\"Context: {context}\\n\\nQuestion: {prompt}\\n\"\n",
    "\n",
    "# response = llm.generate_response(prompt_with_context)\n",
    "# print(response if response else \"No response generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6acc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It depends on the runner type:\n",
      "\n",
      "- x64 \"larger\" runner (Linux 4-core): $0.016/min × 3,000 min = $48.00\n",
      "- arm64 \"larger\" runner (Linux 4-core): $0.01/min × 3,000 min = $30.00\n",
      "- GPU Linux 4‑core (if using GPU): $0.07/min × 3,000 min = $210.00\n",
      "\n",
      "Note: included/free minutes do not apply to larger runners, so these costs would be billed in full. If you meant a different runner type, tell me which one and I’ll recalc.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "token = os.environ[\"GH_TOKEN\"] \n",
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = \"openai/gpt-5-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token,\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a consultant who is an expert in GitHub.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt_with_context,\n",
    "        }\n",
    "    ],\n",
    "    model=model\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
